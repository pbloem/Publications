\documentclass{article}

\usepackage{amsmath,amsfonts,amsthm,fullpage}
\usepackage{color}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{definition}{Definition}

\newcommand{\M}{\mathcal M}
\newcommand{\C}{\mathcal C}
\newcommand{\T}{\mathcal T}
\newcommand{\F}{\mathcal F}
\renewcommand{\P}{\mathcal P}
\newcommand{\K}{\mathcal K}
\newcommand{\X}{\mathcal X}
\newcommand{\B}{\mathbb B}
\newcommand{\D}{\Delta}
\newcommand{\N}{\mathbb N}
\newcommand{\tn}[1]{\textnormal{#1}}
\newcommand{\pair}[1]{\left\langle{#1}\right\rangle}
\newcommand{\concat}{\oplus}
\newcommand{\symb}[1]{\texttt{#1}}

\newcommand{\p}{\quad\text{.}}

\newcommand{\tuple}[1]{\left\langle{#1}\right\rangle}


\newcommand{\sdr}[1]{\textcolor{blue}{\small #1\textsuperscript{[Steven]} }}
\newcommand{\pb}[1]{\textcolor{OliveGreen}{\small #1 \textsuperscript{[Peter]} }}

\newcommand{\argmin}{\mathop{\arg\min}}

\title{Ideal model selection is impossible}
\author{Peter Bloem and Steven de Rooij}

\begin{document}
\maketitle

\begin{abstract}
Kolmogorov complexity provides an objective quantification of the amount of information in an individual binary string, i.e. the number of bits required to effectively describe it, without making any assumptions about the source of that string. However, not all information is created equal -- over the years, there have been many attempts that use two-part codes in order to separate the amount of ``meaningful information'', ``sophistication'' or ``facticity'' of the data, from information representing its random properties. How wonderful would it be if we could quantify not just the syntactic information content of the data  not only syntactically, but the meaningful information as well!

In this paper we show this to be an impossible dream: in general, additional assumptions are required if one wishes to find the true model, or its complexity. This is true regardless of the length or Kolmogorov complexity of the input data. In effect, this means that ideal model selection based on a single data object with no further knowledge is impossible. We unify and contrast the several existing approaches and describe what they can and cannot do. 
\end{abstract}

\section{Definitions}


All numberings should be acceptable!

\begin{definition}[Models and model classes]
  A \emph{model} is a function $f:\{0,1\}^*\to\{0,1\}^*$. A
  \emph{model class} is a set of models. We distinguish four important
  model classes:
  \begin{itemize}
  \item $\C$ is the set of all partial recursive functions,
  \item $\K\subset\C$ is the set of all partial recursive prefix
    functions,
  \item $\T\subset\C$ is the set of all total recursive functions,
  \item $\P\subset\K$ is the set of all prefix functions such that for
    every infinite binary string the function is defined for a
    prefix. This is the natural analogue of totality in the prefix
  \item $\F\subset\P$ contains, for each finite set $S$, a computable
    surjective function maping the binary sequences of length
    $\lceil\log S\rceil$ onto $S$.
  \end{itemize}
\end{definition}

\begin{definition}[Prefix encoding function]
  A prefix encoding function $f:\{0,1\}^*\to\{0,1\}^*$ is an injective
  function that maps the binary strings to a prefix-free set. There
  are prefix encoding functions $g$ with the property that
  $|g(x)|\le|x|+2\log(|x|+2)|$ \cite{TODO}. We fix such a function and
  denote it by $\bar x=g(x)$.
\end{definition}

\begin{definition}[Complexity]
  Let $\phi_1,\phi_2,\ldots$ be a fixed acceptable enumeration of all partial
  recursive functions, e.g. the enumeration described in \cite{TODO}.
  Let $\Pi$ be a computable subset of the natural numbers such that
  $\{\phi_i:i\in\Pi\}$ contains all computable prefix functions. Now
  define Kolmogorov complexity by
\begin{align*}
C(x)&=\min\{|\bar\imath| y:\phi_i(y)=x\},\\
K(x)&=\min\{|\bar\imath| y:\phi_i(y)=x, i\in\Pi\}.\\
\end{align*}
\end{definition}
This definition of $K$ is equivalent to the definition in the
textbook~\cite{TODO}, but it is more convenient for defining the
$K$-complexity of non-prefix functions:

\begin{definition}[Representations]
  A pair $(m,y)$ is a \emph{representation} for $x$ if $m$ is a model
  and $m(y)=x$.
\end{definition}

\begin{definition}[Code length functions]
Define the following code length functions for the representations:
\begin{itemize}
\item $L(m)$ is the length of a self-delimiting description of
  the model $m$, i.e. it is the length function of  a prefix code,
\item $L^m(x)=L(m)+\min\{|y|:m(y)=x\}$ measures the number of bits required to describe both the model $m$ and
  the data $x$ using the model,
\item $L^\M(x)=\min\{L^m(x):m\in\M\}$ measures the number of bits
  required to describe $x$ using the best model in the model class.
\end{itemize}
\end{definition}
  
\begin{definition}[Candidate set]
  The \emph{candidate models} for $x$ from model class $\M$ and
  threshold function $\tau$ are
  \[
  C^\M_\tau(x):=\{m\in\M:L^m(x)\le \tau(x)\}.
  \]
\end{definition}

\begin{definition}[Sophistication]
  The model complexity, sophistication, or facticity, of a string $x$
  given a model class $\M$ and threshold function $\tau$ is defined by
  \[
  S^\M_\tau(x):=\min\{L(m):m\in C^\M_\tau(x)\}.
  \]
\end{definition}

\section{Measures of meaningful information}

\subsection{Koppel Sophistication}

\begin{itemize}
\item Model class is $\T$
\item Threshold function $\tau(x)=L^\M(x)+c$
\item Description method for models is required to be prefix-free, but
  can otherwise be chosen arbitrarily.
\item Koppel uses monotone complexity and discusses infinite strings,
  TODO figure out if and how this affects our results
\end{itemize}

This does not work because of the nickname problem! To fix this:

\begin{definition}
  The complexity of a partial recursive function is defined by
  \begin{align*}
    C(f) &:= \min\{C(i):\phi_i=f\}\\
    K(f) &:= \min\{K(i):\phi_i=f\}.
  \end{align*}
\end{definition}

These definitions make sense because:

\begin{lemma}[Invariance]
Let $\phi_1, \phi_2, \ldots$ and $\psi_1, \psi_2,\ldots$ be two acceptable numberings. There exists a constant $c$ such that $\left| K^\phi(f) - K^\psi(f)\right | \leq c$ for all $f$. \label{lemma:invariance}
\end{lemma}
\begin{proof}
Let $g(i)$ be the function which which translates from $\psi$ to $\phi$.
\begin{align*}
K^\phi(f) &= \min\left\{ K^\phi(i) : \phi_i= f\right\} \\
&\geq \min\left\{ K^\psi(i) : \phi_i= f\right\} - c\\
&= \min\left\{ K^\psi(i) : \psi_{g(i)}= f\right\} - c\\
&\geq \min\left\{ K^\psi(i) : \psi_i= f\right\} - c\\
&= K^\psi(f).
\end{align*}
We can reverse $\phi$ and $\psi$ without loss of generality to achieve the same inequality the other way around, completing the proof.
\end{proof}

Thus, the complexity of a function depends on the choice of
enumeration by no more than a constant term. Note that this implies
that for any enumeration $\psi_1,\psi_2,\ldots$, the complexity $K(\psi_i)$
is less than the literal description length of the index
$|\bar\imath|$ up to a constant. For some numberings, there is a gap
between these two description methods; in those cases, the index is an
inefficient representation of the corresponding function. However it
is possible to construct numberings that are \emph{faithful} in the
sense that no such gap exists:

\begin{definition}[Faithful Numbering]\label{def:faithful}
  A numbering $\psi_1,\psi_2,\ldots$ of the partial recursive
  functions is \emph{faithful} if there is a constant $c$ such that
  for all indices $i$ there is a $j$ such that $\psi_i=\psi_j$ and
  $|j|\le C(\psi_j)+c$.
\end{definition}

\begin{lemma}
  There is a faithful acceptable numbering.
\end{lemma}
\begin{proof}
Let $i_\tn{div}(y)$ be an index such that $\phi_{i_\tn{div}}(y)=\infty$ for all $y$. Define
  \[\psi_q=\begin{cases}
    \phi_{\phi_i(p)}&\tn{if $q$ can be written as $\bar\imath p$ and $\phi_i(p)<\infty$,}\\
    \phi_{i_\tn{div}}&\tn{otherwise.}\end{cases}
  \]
  To show that $\psi$ is faithful, pick any function $f$. Then
\[\begin{split}
C(f)&=\min\{C(i):\phi_i=f\}\\
&=\min\{\min\{|\bar a b|:\phi_a(b)=i\}:\phi_i=f\}\\
&=\min\{|\bar a b|:\phi_{\phi_a(b)}=f\}\\
&=\min\{|\bar a b|:\psi_{\bar a b}=f\}.
\end{split}\]
This shows there is a sufficiently small $\psi$ index.

To show that $\psi$ is acceptable, let $\phi_j$ denote the identity
function. Then a $\phi$-index $i$ can be mapped to a $\psi$-index
using the computable function $r(i)=\bar\jmath i$, so that
$\psi_{r(i)}(y)=\psi_{\bar\jmath i}(y)=\phi_i(y)$. For the reverse,
define $\phi_v(\bar\imath p, y)=\phi_{\phi_i(p)}(y)$. For fixed
$\bar\imath p$, the 
$s^n_m$-theorem (see~\cite{TODO}) states that we can compute the $h$
such that $\phi_h(y)=\phi_v(\bar\imath p,y)$. Let $h(\bar\imath p)$
denote this index as a function of the program; further define
$h(q)=i_\tn{div}$ if $q$ cannot be expressed as $\bar\imath p$. By
construction $h$ is total and computable. To check that the mapping
returns the correct function, rewrite $\phi_{h(\bar\imath
  p)}(y)=\phi_v(\bar\imath p,y)=\phi_{\phi_i(p)}(y)=\psi_{\bar\imath p}(y)$.
\end{proof}

\subsection{Antunes's Coarse Sophistication}

\begin{itemize}
\item Model class is $\T$
\item Description method $L(m)$ for models is unclear, but appears to be
  taken from Koppel, i.e. arbitrary but self-delimiting.
\item Sophistication is defined slightly differently: $S^\T(x)=L(m^*)$ where $m^*=\argmin_m L(m)+L^m(x)-C(x)$. Thus, there is no slack.
\end{itemize}


\subsection{Adriaans' Facticity}

\begin{itemize}
\item Model class is $\C$
\item Description method for models is $L(m)=|\bar\imath|$ where
  $\phi_i=m$. The index function is assumed to be \emph{faithful}, see
  Definition~\ref{def:faithful}
\item Threshold function is $\tau(x)=L^m(x)$.
\item Facticity is actually defined as index length without prefix
  encoding:  $S^\C_0(x):=\min\{|i|:\phi_i\in C^\C_0(x)\}$. But this
  difference is not important for the discussion.
\end{itemize}


\begin{lemma}
  If $\min\{i\ge i_0:|\bar\imath|-K(i)\}$ is an unbounded function of $i_0$, then facticity is bounded.
\end{lemma}
\begin{proof}
Let $\bar\imath p$ be any two-part representation for the data $x$, i.e. $\phi_i(p)=x$. Then construct an alternative two-part representation $\bar vi^* p$, where $i^*$ is the shortest $\psi_u$-program for $i$ such that $\phi_v(i^* p)=\phi_{\psi_u(i^*)}(p) = \phi_i(p)=x$. We compare the lengths of these two representations. Note that $|i^*|=K^\psi(i)$. Therefore,
\[
|\bar\imath p|-|\bar v i^* p| = |\bar\imath|-|\bar v| - |i^*| = |\bar\imath|-|\bar v|-K(i).
\]
By assumption there must be an $i_0$ such that the above expression is positive for all $i>i_0$. From this $i$ onwards, the second representation (using $v$) will have a shorter code length, so $\bar\imath p$ cannot achieve the minimum in the definition of the facticity. Consequently, the facticity is bounded by $F^\phi(x)<|\overline{\imath_0}|$ for all $x$. 
\end{proof}
Note that the condition for this lemma applies to all known partial recursive prefix functions:

\begin{conjecture}
For any partial recursive prefix code length function $L$, the function
\[
\min\{L(i)-K(i):i\ge i_0\}
\]
is unbounded in $i_0$.
\end{conjecture}


\subsection{Roll your own}


\begin{itemize}
\item Model class is either $\C$ or $\K$
\item Description method for models is $L(m)=K(m)$.
\item Threshold function is $\tau(x)=L^m(x)+c$, which matches $C(x)$
  resp. $K(x)$ up to a constant.
\end{itemize}


\begin{lemma}\label{lem:thecoolone}
  Let $\psi_1,\psi_2,\ldots$ be any acceptable enumeration of the partial recursive functions.
  Let $\M$ be any model class, let $\X$ be any set of binary sequences and let $D:\{0,1\}^*\to\N$ be a computable decoding function with a prefix-free domain that maps function descriptions to their indices in $\psi$, i.e. if $f=\psi_{D(p)}$ then $p$ is a $D$-description of $f$. Let $\M'=\{\psi_i:i\in\tn{range}(D)\}$. Further assume there is a constant $c$ such that
\begin{enumerate}
  \item $\forall_{f\in\M'}:\min\{|p|:\psi_{D(p)}=f\}\le K^\psi(f)+c$
  \item $\forall_{x\in\X}:L^{\M',\psi}(x)-L^{\M,\psi}(x)\le c$.
\end{enumerate}
Then is an enumeration $\phi_1,\phi_2,\ldots$ of the partial recursive functions such that $S^\phi_{\M}(x) = |\bar 0|+S^\psi_{\M'}(x)$ for all $x\in\X$.
\end{lemma}
\begin{proof}
We define the numbering $\phi$ as follows:
\[\begin{cases}
\phi_0(p) = 1^r 0 D(p) \\
\phi_{1^r0i}(p) = \psi_i(p) \\
\phi_j(\cdot) = \infty &\text{if $j$ contains no zeroes.}
\end{cases}\]
We will show that under the $\phi$-enumeration, the best representation for $x$ using a model $f\in\M'$ is always better than the best representation using some $f\not\in\M'$.

First suppose $f\in\M'$. Then
\[\begin{split}
K^\phi(f)&=\min\{K^\phi(i):\phi_i=f\}\\
&=\min\{|\bar\jmath q|:\phi_j(q)=i, \phi_i=f\}\\
&=\min\{|\bar\jmath q|:\phi_{\phi_j(q)}=f\}\\
&\le\min\{|\bar0 q|:\phi_{\phi_0(q)}=f\}~\text{(using $j=0$)}\\
&=\min\{|\bar0 q|:\phi_{1^r0 D(q)}=f\}\\
&=|\bar 0|+\min\{|q|:\psi_{D(q)}=f\}\\
&\le K^\psi(f)+c+|\bar 0|,
\end{split}
\]
where the last inequality uses the first assumption.


Now assume that the best model $f$ for $x$ is not in $\M'$. 
Let $i$ be the index of $f$ with the shortest description, i.e. it achieves the minimum in
\[
K^\phi(f)=\min\{K^\phi(i):\phi_i=f\}.
\]
There are two possibilities. Either $i=0$, in which case we have $K^\phi(f)\ge r$ because $\phi_0$ cannot output zero and all other $\phi$-programs are at least $r$ bits long.

Otherwise, we can bound
\[\begin{split}
K^\phi(f)&=K^\phi(i)=K^\phi(1^r0j)\\
&\ge K^\phi(j)-c'\\
&\ge K^\psi(j)+r+1-c'\\
&\ge\min\{K^\psi(j):\phi_j=f\}+r+1-c'\\
&=K^\psi(f)+r+1-c'.
\end{split}
\]
Now choose $r=c''+\max\{K^\psi(\phi_0),c'-1\}$. Then substitution yields, for both cases, 
$K^\phi(f)\ge c''+K^\psi(f)$.

Combining the inequalities above, for any model $g\not\in\M'$, there is a model $f\in\M$ such that
\[\begin{split}
K^\phi(g)+C^g(x) &\ge K^\psi(g)+C^g(x)+c''\\
&\ge K^\psi(f)+C^f(x)-c+c''\\
&\ge K^\phi(f)+C^f(x) -2c+c'' -|\bar0|.
\end{split}\]

By choosing $c''$ sufficiently large, we can ensure that the best representation is in $\M'$ for all $x\in\X$, which completes the proof.
\end{proof}

\paragraph{TODO: instantiate for UTM}

\begin{itemize}
\item Model class is $\K$
\item Description method for models is $L(m)=K(m)$.
\item Threshold function is $\tau(x)=L^m(x)+c$, which matches $K(x)$
  up to a constant.
\end{itemize}


\begin{lemma}
Let $\M$ be a prefix model class where for every $x\in\X$ there is a singleton model $f\in\M$ with $f(\epsilon)=x$. Then there is an enumeration $\phi_1,\phi_2,\ldots$ of the prefix partial recursive functions, and a constant $c$, such that
\[
K(x)-S^{\M,\phi}(x)\le c
\]
for all $x\in\X$.
\end{lemma}
\begin{proof}
Let $\psi_1,\psi_2,\ldots$ be any default enumeration of the partial recursive prefix functions. Note that since $f$ is a prefix function, if $f$ is defined for input $\epsilon$ then it cannot be defined for any other input. Pick $f,x$ with $f(\epsilon)=x$. Note that $x$ can be computed from $f$ and a fixed program, so there is a $c$ such that $K(x)\le K(f)+c$. Vice versa, given any $x$ we can construct an index of $f$, since $\psi$ is an acceptable numbering. Therefore $|K(f)-K(x)|\le c$.

We now define a computable function $D$ by $D(\bar\imath p)=j$ where $\psi_j(\epsilon) = \psi_i(p)$.  We will show that the two conditions of Lemma~\ref{lem:thecoolone} hold for the prefix function $D$.

\begin{enumerate}
\item Let $f$ be any function in the range of $D$, and $x$ its output. Then $\min\{|p|:\psi_{D(p)}=f\}=\min\{|\bar\imath q|:\psi_i(q)=x\}=K(x)\le K(f)+c$.
\item On the one hand $L^{\M',\psi}(x)\le K(f)+|\epsilon|\le K(x)+c$. On the other hand, $L^{\M,\psi}(x)$ is an effective description of $x$, so $K(x)$ is at most a constant larger.
Together, these inequalities establish the second condition.
\end{enumerate}

Then by Lemma~\ref{lem:thecoolone} there is an enumeration $\phi_1,\phi_2,\ldots$ such that $S^{\M,\phi}(x)=|\bar 0|+S^{\M',\psi}(x)$. We observed that $|K(f)-K(x)|\le c$ for any $f\in\M'$, so $S^{\M',\psi}(x)\ge K(x)+c$. This proves the lemma.
\end{proof}

\subsection{Kolmogorov's Structure Function}

\begin{itemize}
\item Model class is $\F$
\item Description method for models $L(m)=K(S)$ where $S$ is the range
  of $m$. There is some ambiguity as to the definition of prefix
  complexity for finite sets; discuss and refer to Shen \cite{TODO}.
\end{itemize}

\subsection{Vit\'anyi's Sophistication / Meaningful Information}

\begin{itemize}
\item Model class is $\T$
\item Description method for models is $L(m)=K(m)$
\item Candidate set is defined differently: $C_c=\{m\in\T:|L^m(x)-K(x)|\le
  c\}$. There appears to be a problem with this definition, because
  the two-part descriptions of $x$ may be shorter than $K(x)$ by
  exploiting the fact that the models do not need to be prefix functions.
\end{itemize}

% stru fu: model class is all finite sets
% code length L(m)+L_m(x)
% acceptability criterion acc(m) = 2L(m)+L_m(x)-C(x)
% 


\section{Notes}

Do we have the citation ``Paul M. B. Vit\'anyi: Meaningful Information. IEEE Transactions on Information Theory 52(10): 4617-4626 (2006)''?

(From Koppel, Complexity, Depth and Sophistication:)

``Sophistication is a generalization of the "H-function" or "minimal sufficient statistic" of Cover and Kolmogoroff, using the motonic complexity of Levin: is Cover the original source for the idea of a ``minimal sufficient statistic''? Also Koppel does indeed use monotonic complexity as in Levin. We need to know at least a little about the difference between monotonic and regular KC: is it less than a logarithmic additive term? If so, we can conveniently sweep it under the rug.

\section{Plan}

Idee van Sophistication: gebruik two-part coding om een scheiding te maken tussen structuur van de data (modelinformatie) en de ruis.


Perhaps surprisingly, it is also reinforced by Vit\'anyi, when he writes : (From Vereshchagin and Vit\'anyi, ``Kolmogorov’s Structure Functions and Model Selection'':)
\begin{quotation}
  This expression emphasizes the two-part code nature of Kolmogorov complexity. In the example
\[x=10101010101010101010101010\]
we can encode $x$ by a small Turing machine printing a specified number of copies of the pattern `10' which computes $x$ from the program `13'.” This way, $K(x)$ is viewed as the shortest length of a two-part code for $x$, one part describing a Turing machine, or model, for the regular aspects of $x$, and the second part describing the irregular aspects of $x$ in the form of a program to be interpreted by $T$. The regular, or “valuable,” information in  is constituted by the bits in the “model” while the random or ``useless'' information of $x$ constitutes the remainder.
\end{quotation}






Inherent property of the data: 
\begin{itemize}
\item Should be a two-part effective description of $x$
\item Invariant: $\exists c:\forall x:|S^1(x)-S^2(x)|\le c$
\item Both structure and noise are unbounded
\end{itemize}

Conjecture: er is geen functie van de data die aan bovenstaande eisen voldoet.



\subsection{Review}
Onderscheid op basis van drie properties:
\begin{itemize}
\item Model class: total / partial. Reden voor total: bij partial rec. is de UTM in het model, collapse, citaten. Nadeel: arbitraire beperking op de beschrijvingskracht, dus minder universeel
\item Models are prefix functions / not prefix functions: viz $C$ vs $K$. Als wel prefix, dan gaat alles makkelijker kapot. Als niet prefix dan wordt de balans verstoord, het wordt moeilijk als de balans ook de andere kant op wordt verstoord door de modelklasse te beperken: die twee handicaps zijn moeilijk te vergelijken.
\item Model length is prefix encoded index length / $K(f)$: compact numberings, bespiegeling over of het gat tussen $|\bar\imath|$ en $K(\phi_i)$ unbounded is. Wat is nu eigenlijk de two-part code precies, is dat $K$ als white box of is $K$ gebruikt voor het eerste deel? Ook beetje vreemd om in de eerste visie modelklassen te introduceren.
\end{itemize}

Bestaande aanpakken:
\begin{itemize}

\item Facticity: partial / niet prefix: bounded

\item Paul's sophistication: Sufficient statistic: alles wat $K$-complexiteit haalt tot op slack $c$. Minimal sufficient statistic minimaliseert daarover de modelgrootte. Model bevat totale prefixfuncties. Noise is bounded.

\item total / niet prefix, o.a. coarse sophistication. We geloven invariantie niet. Voor alle shallow strings bounded (nog niet bewezen, maar werkt door alles total te maken met vaste grote maar computable time bound)

\end{itemize}

\subsection{Conclusion}
Stel onze conjecture is waar, is het dan helemaal nutteloos? Nee, want lengte van two-part representations is nog steeds een redelijke maat voor counterevidence against a model. No-hypercompression, $p$-values, randomness deficiency. Probleem zit in harde cutoffs zoals minimalisatie en een vaste constante waarboven representaties niet meer meedoen. Daar gaat invariantie van kapot.

Onze mening: als onze conjecture waar is, dan moet je constraints weglaten: maak het makkelijk en doe prefix functies en alle partial recursive functions, en accepteer de collapse gewoon. Maar dat betekent weer dat je een hele wolk van two-part optimale representaties hebt waar je niet tussen moet willen kiezen.

Er is een gat tussen $K(f)+|y|-K(x)$ en $\delta(x\mid f)$. De laatste is de juiste maat voor de counterevidence tegen $f$.

\section{Thoughts and questions}

\begin{itemize}
\item Paul argues bleurg that the randomness deficiency of a model is a measure of the amount of structure left in the noise part. I feel that it is also a measure of the amount of counterevidence against a model in the statistical sense, as follows: the randomness deficiency of $x$ given model $M$ is $\delta(x|M)=L_M(x)-K(x|M)$. Suppose that model $M$ is true. We can then use the no hypercompression inequality to rewrite:
%
\[
P_{x\sim M}(\delta(x|M)\ge c) = P_{x\sim M}(L_M(x) - K(x|M) \ge c)\le 2^{-c}
\]
Thus, if $M$ is true the probability of a large randomness deficiency is exponentially small! This amount of evidence is robust in the sense that changing the UTM around will change the amount of evidence by at most a constant. If the structure function is going to give us a \emph{cloud} of candidate models instead of just a single one, I think this is a really nice interpretation of the meaning of that cloud: we simply measure the available evidence against all individual models.  

\item Shen explains the collapse of the structure function if you use enumerating complexity rather than listing complexity. How can we most cleanly explain that this collapse does not vanish for weaker model classes?

\item Properties of representations on $K(M)$ vs $L_M(x)$ graph: diagonals identify representations with the same two-part codelength. The randomness deficiency is the distance to the minimum, which is the $K(x)$ diagonal:
\[L(x;M)=K(M)+L_M(x) =K(M)+K(x|M)+L_M(x)-K(x|M)  = K(x)+\delta(x|M).\]
 Models move horizontally by a constant when the ordering of TMs is changed. Thus the randomness deficiency and two part code are also changed by at most a constant. In contrast the \emph{minimum} can now be achieved by a very different representation.

\item ``Power and peril of MDL'': bespreken ook de ``collapse of the structure function'' als de model class te sterk is, dwz sets worden te efficient gecodeerd (wsch equivalent met Shen's enumerating complexity).

\end{itemize}

\appendix
\section{Dead darlings}

\begin{definition}
Given an enumeration $\phi_1,\phi_2,\ldots$ of the partial recursive functions, and an enumeration $\psi_1,\psi_2,\ldots$ of the partial recursive prefix functions. Let $\psi_u$ be a universal element with property $\psi_u(\bar\imath p)=\psi_i(p)$. Then define $v$ by
\[
v(a p)=\begin{cases}\phi_{\psi_u(a)}(p)&\tn{if $a$ is in the domain of $\psi_u$,}\\
\infty&\tn{otherwise}.\end{cases}
\]
\end{definition}
\begin{lemma}
The function $v=\phi_v$ as defined above is partial recursive.
\end{lemma}
\begin{proof}
Let $r$ be the input of $v$. Simulate $\psi_u$ using a TM with a one-way read-only input tape. If the TM does not halt, then enter an infinite loop. Otherwise, let $r=ap$ where $a$ is the part of the input tape that has been read when the TM halts, and let $i$ be the output of the TM. Now simulate $\phi_i$ on input $p$.
\end{proof}

\begin{lemma}
Assume the prefix function $\bar\cdot$ used in the definition of complexity is such that $\bar x-x$ is monotonically increasing. Let $\psi_1,\psi_2,\ldots$ be any acceptable numbering. Then for every $c$ there is another acceptable numbering $\phi_1,\phi_2,\ldots$ such that for all partial recursive functions $f$ we have
\[
K^\phi(f)-K^\psi(f) \ge c.
\] \label{lemma:building-block}
\end{lemma}
\begin{proof}
First note that there is a $c'$ such that 
\begin{equation}
	K(1^r 0  x) + c' \geq K(x) \label{eq:prelim1}
\end{equation}
for all $x$, since we can create a program that first runs the shortest program for $1^r 0 x$ and then strips the prefix $1^r 0$ from the result.

Define $\phi_{1^r0i}(x) = \psi_{i}(x)$, with $\phi_{j}(x) = \infty$ if $j$ does not contain a zero. Intuitively, any $\phi$-program is $r+1$ bits longer than the corresponding $\psi$-program. However, the used prefix function complicates this slightly. But all we need is the bound
\begin{equation}\label{eq:prelim2}\begin{split}
K^\phi(x) &= \min \{ |\overline{1^r 0 \imath}| y : \phi_{1^r 0 i}(y) = x \}\\
&  \ge \min\{|1^r0\bar\imath y| : \phi_{1^r 0 i}(y) = x \}\qquad\tn{(using assumption on $\bar\cdot$)}\\
& = r+1 +\min\{|\bar\imath y| : \psi_i(y) = x \}\\
& = r+1+K^\psi(x).
\end{split}\end{equation}

We can now relate the complexity of $f$ under the two enumerations as follows:
\begin{align*}
K^\phi(f) &= \min\left\{ K^\phi(j) : \phi_j = f \right\}& \\
       &= \min\left\{ K^\phi(1^r0i) : \phi_{1^r0i} = f \right\}& \\
       &\ge  \min\left\{ K^\phi(i) : \phi_{1^r0i} = f \right\}-c'&\text{by~\eqref{eq:prelim1}}\\
       &\geq \min\left\{ K^\psi(i)  : \phi_{1^r0i} = f \right\}+r+1-c'& \text{by \eqref{eq:prelim2}}\\
       &= \min\left\{ K^\psi(i) : \psi_{i} = f \right\} + r+1 -c'& \\
       &= K^\psi(f) + r + 1 - c'.
\end{align*}
The proof is completed by choosing $r=c+c'-1$.
\end{proof}

\begin{definition}
  An enumeration $\phi_1,\phi_2,\ldots$ of the partial recursive
  functions is called \emph{compact} if for all $i,y$ there is a $j$
  such that $|j|\le|i y|$ and $\phi_i(y z)=\phi_j(z)$ for all $z$.
\end{definition}

\begin{lemma}
There is a compact acceptable numbering.
\end{lemma}
\begin{proof}
  Let $\phi_1,\phi_2,\ldots$ be any acceptable numbering. Let $\psi_1,\psi_2,\ldots$ be a new acceptable numbering defined by $\psi_j(x)=\phi_i(y x)$ if $j$ is a pair satisfying $j=\bar\imath y$, and $\psi_j(x)=\infty$ otherwise.  We will show that $\psi$ is both $0$-compact and acceptable. 

To show compactness, pick any index $i$ and binary string $y$. First assume $i$ is a valid pair $i=\bar a b$. Then  $\psi_i(y x) = \psi_{\bar a b}(y x)=\phi_a(b y x)$, but also $\psi_{\bar a b y}(x)=\phi_a(b y x)$, so $\psi_i(y x) = \psi_j(x)$ for $j=\bar a b y$; so $|j|=|iy|+0$. On the other hand, if $i$ is not a valid pair, we can simply use $j=i$ so that $\psi_i(y x)=\psi_j(x)=\infty$ for all $x$.

To show that $\psi_1,\psi_2,\ldots$ is acceptable, we define total
computable functions $f$ and $g$ such that $\psi_i(x)=\phi_{f(i)}(x)$
and $\phi_j(x)=\psi_{g(j)}(x)$. The easy direction is
$g(j)=\bar\jmath\epsilon$. The definition of the mapping in the other
direction $f(i)$ depends on whether $i$ is a valid pair. If it is not,
then $f(i)=h$ for some $h$ such that $\phi_h(x)=\infty$ for all $x$. On the other hand if $i=\bar\jmath y$, then $f(i)$ is the index of a partial recursive function $\phi_{f(i)}(x)$ defined by a Turing machine that simulates the machine for $\phi_j$ but with $yx$ on the input tape.
\end{proof}


\begin{lemma}
Compact numberings are sort of faithful.
\end{lemma}
\begin{proof}
First, let $v$ be the index of the partial recursive function given by $\phi_v(\bar k p x)=\phi_{\phi_k(p)}(x)$. Let $\bar k p$ be a shortest program for $i$, that is $|\bar k p| = K(i)$ and $\phi_k(p)=i$. Then $\phi_i(x)=\phi_v(\bar k \bar p x)$. We now use compactness to find an index $j$ with $\phi_v(\bar k \bar p x)=\phi_j(x)$ and length
\[|j|\le |v\bar k\bar p|\le|v|+|\bar k p|+2\log|\bar k p|=K(i)+|v|+2\log K(i),\]
as required.
\end{proof}


\bibliographystyle{plain}
\bibliography{facticity}

\end{document}
