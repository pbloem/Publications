\documentclass{article}

\usepackage{charter}
\usepackage{eulervm}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{authordate1-4}
\usepackage{url}

\theoremstyle{definition}
\newtheorem*{thm}{Theorem}
\newtheorem{lma}{Lemma}
\newtheorem*{dfn}{Definition}
\newtheorem*{exm}{Example}
\usepackage{lscape}

\title{Complexity Measures for Graphs}
\author{Peter Bloem}
\date{\today}

% non-indented, spaced paragraphs
\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.1in}

\begin{document}

\maketitle

\begin{abstract}
\noindent This document presents some complexity measures on graph data. We focus specifically on those measures that are designed for `complex networks': large graphs like social networks, technological networks and biological networks.
\end{abstract}

\section*{Complexity measures}
\subsection*{Basic graph measures}
\begin{description}
\item[Number of nodes ($N$)] A count of the number of nodes (or vertices) in the network.
\item[Number of links ($L$)] A count of the number of links (or edges) in the network. 
\item[Mean degree ($\bar{d}$)] The mean number of nodes a node is connected to.
\item[Degree standard deviation ($\sigma_d$)]  The sample standard deviation of the degrees.
\item[Size of the largest component ($W$)] Size of the largest connected subgraph.
\item[Proportion of the largest component ($W_p$)] The size of the largest connected subgraph divided by the size of the total graph. (Note that rounding will sometimes cause this to appear as 1.0, even when the largest component is smaller than the total graph).
\item[Diameter of the largest component ($D$)] If we define the distance between two nodes as the length of the shortest path, then the diameter is the longest posssible distance in the graph. If the graph is not connected, then the diameter is infinite, so we report the diameter of the largest connected component.  
\item[Mean distance ($M$)] The mean distance between two nodes. A large network with a small mean distance is said to have the \textit{small world} property, ie. there is likely to be a short path between any to nodes.
\item[Clustering Coefficient ($C$, $C_{WS}$)] The clustering coefficient measures the level of \textit{transitivity in the network}. For instance, if system a on the internet is connected to system b, and b is connected to system c, with what probability can we say that a connects to c also.

There is also a local clustering coefficient $C_i$, which is the same but only for the neighbouring nodes of node $i$. The mean local clustering coefficient we call $C_{WS}$. The two values  
\end{description}
\subsection*{Scale free networks ($\alpha$,$p_\alpha$)}

The degree distribution (the probability that a node has a given number of neighbours) is one of the most telling attributes of a network. In particular the networks for which the degree distribution follows a power law are interesting. These networks are called \emph{scale free}, and they have many  interesting characteristics, such as a tolerance to random attacks and the small world property. \cite{barabasi1999emergence}

If the degree distribution follows a power law, we refer to its exponent as $\alpha$.
The significance level of the conclusion that the degree distribution follows a power law we call $p_\alpha$. If this value is greater than 0.1 we consider the power law a reasonable model, and report the exponent. All methods for determining significance and exponents were taken from \cite{clauset2007power}.

\subsection*{Assortative mixing ($r$)}

Another important property of a network is whether nodes are likely to be connected to nodes that are similar, for some measure of similarity. Nodes in friendship networks, for instance tend to be connected to nodes with similar properties (gender, height, ethnicity). This is called assortative mixing. An example of disassortative mixing is a sexual contact network, where the majority of links are between different genders.

We can also test for assortative mixing by structural properties of the graph. Most commonly, the degree of nodes is used for this. For instance, do people with many friends tend to be friends with other people with many friends, or do websites with many links often link to other websites with many links.

The most common measure for Assortative mixing by degree is the Pearson correlation coefficient between the degrees on either side of an edge. We call this value $r$. Since $r$ represents a correlation, it ranges from -1 to 1, with -1 being perfect disassortive mixing and 1 being perfect assortative mixing. 

A high value of $r$ is associated with resilience to targeted attack.

\subsection*{Self-similarity ($d_B$)}

For data sets like point patterns, metric data of tabular data, the notion of dimension can be a very descriptive property. There are many methods that allow on to measure the intrinsic dimension of the dataset, without considering the specifics of its representation. 

Almost all notions of intrinsic dimension rely on so called scaling laws. A scaling law relates a one dimensional measure $x$ (like the width of a box) to some measure over the dataset $y$ (like the number of point that fall in a box). The laws of geometry then tell us that these should be (roughly) related as $y \sim x^\alpha$, where $\alpha$ is the intrinsic dimension of the dataset.

If we try a similar approach with networks we will soon see it fall down. If for instance, we take some random node in a small-world network and ask how many nodes $N(l)$ are within a distance $l$ of it, the small-world property will ensure that most nodes are within a small distance. The growth will be logarithmic rather than polynomial.

To find an analogue to dimension for networks, Song et al @!cite devise the following method: cover the network in clusters of nodes called boxes, such that each box has a maximum distance between any two nodes of $l_B$. If we create a new network with a node for each box and links between nodes if these is a single-step connection between the corresponding boxes, we find that this new (smaller) network will, for many networks, have the same degree distribution as the old. Applying the procedure again will have the same result. In this sense, the network is said to be \emph{self-similar}.

If we apply a single step for different values $l_B$ and count the resulting number of boxes $N_B(l_B)$, we find the following relation for self-similar networks:
\[
\frac{N_B(lb)}{N} \approx l_B^{d_B}
\]
Where $N$ is the number of nodes in the network and $d_B$ is a characteristic scaling exponent of the network, analogous to dimension. The exact properties of this self-fimilar scaling have not been fully investigated, but some relation has been found between robustness and self similarity. @! Cite


\subsection*{Compressibility}
The minimum/maximum compression ratio $\kappa_{\mbox{min}}$, $\kappa_{\mbox{max}}$ and the median $ \bar{\kappa}$

\section*{Introduction}

\section*{Data}

We test these complexity measures on the following datasets.

\subsection*{Technological networks}

\subsubsection*{The internet}

The internet is a classic example of a large, complex network. So large, in fact that we have little hope capturing a full snapshot of the whole thin at once. The best we can do is to capture some part of it using traceroutes. We have two datasets, each representing autonomous systems as vertices, with edges between those that are directly connected.

The large dataset was downloaded from the Stanford Large Network Dataset Collection(\url{http://snap.stanford.edu/data/as-skitter.html}), and it contains roughly 1.7 million nodes. @! Cite

The smaller dataset was downloaded from the personal page of Mark Newman (\url{http://www-personal.umich.edu/~mejn/netdata/}), and it contains @!Cite

\subsubsection*{The world wide web}
\subsection*{Social networks}
\subsubsection*{Epinions}
\subsubsection*{Actor network}

\subsection*{Biological networks}
\subsubsection*{E. Coli Cellular network}
\subsubsection*{C. Elegans Neural Network}


\subsection*{RDF Data}
\subsubsection*{IAFB Dataset}


\section*{Code}

The code is written in Java, using the JUNG graph library. All code is available in GitHub in the following repsitories.
\begin{description}
\item[D2S Tools] (\url{https://github.com/Data2Semantics/d2s-tools}) Common code shared by WP1 and WP2.
\item[Lilian] (\url{https://github.com/pbloem/Lilian}) Implementation of the complexity measures, including some tools for running experiments, and much unrelated code.
\end{description}

\begin{landscape}

\section*{Results}

\begin{tabular}{l | r r r r r r r r r r r r r r r }
  \hline
    & $N$ & $L$ & $W$ & $W_p$ & $D$ & $M$ & $C$ & $C_{\mbox{WS}}$ & $\alpha$ & $p_\alpha$ & $r$ & $d_B$ & $\bar{\kappa}$ & $\kappa_{\mbox{min}}$ & $\kappa_{\mbox{max}}$  \\
    \hline
 Internet (big) & N & L & W & Wp & D & C & C WS & alpha & p alpha & r & dB & kappa & kappa min & kappa max \\
 Internet (small) & N & L &  W & Wp & D & C & C WS & alpha & p alpha & r & dB & kappa & kappa min & kappa max \\    
 WWW & & & & & & & & & & & & & & & km \\
 Epinions & & & & & & & & & & & & & & & km \\ 
 Actors  & & & & & & & & & & & & & & & km \\
 E. Coli  & & & & & & & & & & & & & & & km \\
 C. Elegans  & & & & & & & & & & & & & & & km \\
 IAFB  & & & & & & & & & & & & & & & km \\ 
 \hline

\end{tabular}

\end{landscape}

\bibliographystyle{authordate3}
\bibliography{citations}

\end{document}